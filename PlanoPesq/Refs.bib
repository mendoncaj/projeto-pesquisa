@article{Arash2016,
abstract = {Purpose – The use of social media and in particular community Question Answering (Q{\&}A) websites by learners has increased significantly in recent years. The vast amounts of data posted on these sites provide an opportunity to investigate the topics under discussion and those receiving most attention. The purpose of this paper is to automatically analyse the content of a popular computer programming Q{\&}A website, StackOverflow (SO), determine the exact topics of posted Q{\&}As, and narrow down their categories to help determine subject difficulties of learners. By doing so, the authors have been able to rank identified topics and categories according to their frequencies, and therefore, mark the most asked about subjects and, hence, identify the most difficult and challenging topics commonly faced by learners of computer programming and software development. Design/methodology/approach – In this work the authors have adopted a heuristic research approach combined with a text mining approach to investigate the topics and categories of Q{\&}A posts on the SO website. Almost 186,000 Q{\&}A posts were analysed and their categories refined using Wikipedia as a crowd-sourced classification system. After identifying and counting the occurrence frequency of all the topics and categories, their semantic relationships were established. This data were then presented as a rich graph which could be visualized using graph visualization software such as Gephi. Findings – Reported results and corresponding discussion has given an indication that the insight gained from the process can be further refined and potentially used by instructors, teachers, and educators to pay more attention to and focus on the commonly occurring topics/subjects when designing their course material, delivery, and teaching methods. Research limitations/implications – The proposed approach limits the scope of the analysis to a subset of Q{\&}As which contain one or more links to Wikipedia. Therefore, developing more sophisticated text mining methods capable of analysing a larger portion of available data would improve the accuracy and generalizability of the results. Originality/value – The application of text mining and data analytics technologies in education has created a new interdisciplinary field of research between the education and information sciences, called Educational Data Mining (EDM). The work presented in this paper falls under this field of research and it is an early attempt at investigating the practical applications of text mining technologies in the area of computer science (CS) education.},
author = {Arash, Michael and English, E and Mahdi},
file = {:Users/mendonca/mestrado/projeto{\_}pesquisa/artigos/JEIM-11-2014-0109.pdf:pdf},
journal = {Journal of Enterprise Information Management Journal of Enterprise Information Management Journal of Enterprise Information Management Web of Science Database Library Review},
number = {3},
pages = {255--275},
title = {{Text mining stackoverflow An insight into challenges and subject-related difficulties faced An insight into challenges and subject-related difficulties faced by computer science learners subject-related difficulties faced by computer science learners}},
url = {http://dx.doi.org/10.1108/JEIM-11-2014-0109},
volume = {29},
year = {2016}
}
@article{Ferrucci,
abstract = {In 2007, IBM Research took on the grand challenge of building a computer system that could compete with champions at the game of Jeopardy!i. In 2011, the open-domain question-answering (QA) system, dubbed Watson, beat the two highest ranked players in a nationally televised two-game Jeopardy! match. This paper provides a brief history of the events and ideas that positioned our team to take on the Jeopardy! challenge, build Watson, IBM Watsoni, and ultimately triumph. It describes both the nature of the QA challenge represented by Jeopardy! and our overarching technical approach. The main body of this paper provides a narrative of the DeepQA processing pipeline to introduce the articles in this special issue and put them in context of the overall system. Finally, this paper summarizes our main results, describing how the system, as a holistic combination of many diverse algorithmic techniques, performed at champion levels, and it briefly discusses the team's future research plans.},
author = {Ferrucci, D A},
doi = {10.1147/JRD.2012.2184356},
file = {:Users/mendonca/Library/Application Support/Mendeley Desktop/Downloaded/Ferrucci - Unknown - Introduction to This is Watson.pdf:pdf},
title = {{Introduction to This is Watson}}
}
@article{Joorabchi2015,
abstract = {The uncontrolled nature of user-assigned tags makes them prone to various inconsistencies caused by spelling variations, synonyms, acronyms and hyponyms. These inconsistencies in turn lead to some of the common problems associated with the use of folksonomies such as the tag explosion phenomenon. Mapping user tags to their corresponding Wikipedia articles, as well-formed concepts, offers multifaceted benefits to the process of subject metadata generation and management in a wide range of online environments. These include normalization of inconsistencies, elimination of personal tags and improvement of the interchangeability of existing subject metadata. In this article, we propose a machine learning-based method capable of automatic mapping of user tags to their equivalent Wikipedia concepts. We have demonstrated the application of the proposed method and evaluated its performance using the currently most popular computer programming Q{\&}A website, StackOverflow.com, as our test platform. Currently, around 20 million posts in StackOverflow are annotated with about 37,000 unique user tags, from which we have chosen a subset of 1256 tags to evaluate the accuracy performance of our proposed mapping method. We have evaluated the performance of our method using the standard infor-mation retrieval measures of precision, recall and F 1 . Depending on the machine learning-based classification algorithm used as part of the mapping process, F 1 scores as high as 99.6{\%} were achieved.},
author = {Joorabchi, Arash and English, Michael and Mahdi, Abdulhussain E},
doi = {http://dx.doi.org/10.1177/0165551515586669},
file = {:Users/mendonca/mestrado/projeto{\_}pesquisa/artigos/instrucoes{\_}plano{\_}pesquisa{\_}2015.pdf:pdf},
issn = {1550-0594},
journal = {Article Journal of Information Science},
keywords = {Semantic mapping,StackOverflow,Wikipedia,subject metadata,user tags},
number = {5},
pages = {570--583},
pmid = {24131618},
title = {{Automatic mapping of user tags to Wikipedia concepts: The case of a Q{\&}A website – StackOverflow}},
volume = {41},
year = {2015}
}
@article{Manning2009,
abstract = {Class-tested and coherent, this groundbreaking new textbook teaches web-era information retrieval, including web search and the related areas of text classification and text clustering from basic concepts. Written from a computer science perspective by three leading experts in the field, it gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. All the important ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science. Based on feedback from extensive classroom experience, the book has been carefully structured in order to make teaching more natural and effective. Although originally designed as the primary text for a graduate or advanced undergraduate course in information retrieval, the book will also create a buzz for researchers and professionals alike.},
archivePrefix = {arXiv},
arxivId = {0521865719 9780521865715},
author = {Manning, Christopher D. and Raghavan, Prabhakar and Schutze, Hinrich},
doi = {10.1109/LPT.2009.2020494},
eprint = {0521865719 9780521865715},
file = {:Users/mendonca/mestrado/projeto{\_}pesquisa/books/irbookprint.pdf:pdf},
isbn = {0521865719},
issn = {13864564},
journal = {Online},
keywords = {keyword},
number = {c},
volume = {1},
pages = {569},
pmid = {10575050},
title = {{An Introduction to Information Retrieval}},
url = {http://dspace.cusat.ac.in/dspace/handle/123456789/2538},
year = {2009}
}
@inproceedings{Mihalcea2007,
abstract = {Proceedings of NAACL HLT 2007, pages 196-203, Rochester, NY, April 2007. ccopyright2007 Association for Computational Linguistics for Rada Mihalcea Department of},
author = {Mihalcea, R},
booktitle = {Proceedings of NAACL HLT},
pages = {142--147},
title = {{Using Wikipedia for Automatic Word Sense Disambiguation}},
url = {http://acl.ldc.upenn.edu/n/n07/n07-1025.pdf},
volume = {2007},
year = {2007}
}
@article{Mihalcea2001,
abstract = {Abstract The goal of the Semantic Web is to create a new form of Web content meaningful to computers. The Semantic Web aims to provide greater functionality, via intelligent tools such as information extractors, brokers, reasoning services or question answering systems. ... $\backslash$n},
author = {Mihalcea, R F and Mihalcea, S I},
doi = {10.1109/ICTAI.2001.974475},
file = {:Users/mendonca/Library/Application Support/Mendeley Desktop/Downloaded/Mihalcea, Mihalcea - 2001 - Word Semantics for Information Retrieval Moving One Step Closer to the Semantic Web.pdf:pdf},
isbn = {0-7695-1417-0},
issn = {10636730},
journal = {13th IEEE International Conference on Tools with Artificial Intelligence. ICTAI 2001},
pages = {280--287},
title = {{Word Semantics for Information Retrieval: Moving One Step Closer to the Semantic Web}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=974475{\%}5Cnpapers2://publication/doi/10.1109/ICTAI.2001.974475},
year = {2001}
}
@article{Mihalcea2004,
abstract = {In this paper, we introduce TextRank a graph-based ranking model for text processing, and showhowthis model can be successfully used in natural language applications. In particular, we propose two innovative unsupervised methods for keyword and sentence extraction, and show that the results obtained compare favorably with previously published results on established benchmarks.},
author = {Mihalcea, Rada and Tarau, Paul},
doi = {10.3115/1219044.1219064},
isbn = {9781605581934},
issn = {0256307X},
journal = {Proceedings of EMNLP},
pages = {404--411},
title = {{TextRank: Bringing order into texts}},
url = {http://acl.ldc.upenn.edu/acl2004/emnlp/pdf/Mihalcea.pdf},
volume = {85},
year = {2004}
}
@article{Miotto2013,
abstract = {Clinical text, such as clinical trial eligibility criteria, is largely underused in state-of-the-art medical search engines due to difficulties of accurate parsing. This paper proposes a novel methodology to derive a semantic index for clinical eligibility documents based on a controlled vocabulary of frequent tags, which are automatically mined from the text. We applied this method to eligibility criteria on ClinicalTrials.gov and report that frequent tags (1) define an effective and efficient index of clinical trials and (2) are unlikely to grow radically when the repository increases. We proposed to apply the semantic index to filter clinical trial search results and we concluded that frequent tags reduce the result space more efficiently than an uncontrolled set of UMLS concepts. Overall, unsupervised mining of frequent tags from clinical text leads to an effective semantic index for the clinical eligibility documents and promotes their computational reuse.},
author = {Miotto, Riccardo and Weng, Chunhua},
doi = {10.1016/j.jbi.2013.08.012},
file = {:Users/mendonca/mestrado/poli-usp/metodologia/1-s2.0-S1532046413001408-main.pdf:pdf},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
number = {6},
pages = {1145--1151},
title = {{Unsupervised mining of frequent tags for clinical eligibility text indexing}},
volume = {46},
year = {2013}
}
@article{Posch2014,
archivePrefix = {arXiv},
arxivId = {1603.06494},
author = {Posch, Lisa},
doi = {10.1007/978-3-319-11915-1_36},
eprint = {1603.06494},
file = {:Users/mendonca/mestrado/projeto{\_}pesquisa/artigos/1603.06494v1.pdf:pdf},
isbn = {9783319119144},
issn = {16113349},
journal = {Proceedings of the 13th International Semantic Web Conference},
pages = {537--544},
title = {{Enriching Ontologies with Encyclopedic Background Knowledge for Document Indexing}},
year = {2014}
}
@article{Roul2015,
abstract = {With the rising quantity of textual data available in electronic format, the need to organize it become a highly challenging task. In the present paper, we explore a document organization framework that exploits an intelligent hierarchical clustering algorithm to generate an index over a set of documents. The framework has been designed to be scalable and accurate even with large corpora. The advantage of the proposed algorithm lies in the need for minimal inputs, with much of the hierarchy attributes being decided in an automated manner using statistical methods. The use of topic modeling in a pre-processing stage ensures robustness to a range of variations in the input data. For experimental work 20-Newsgroups dataset has been used. The F- measure of the proposed approach has been compared with the traditional K-Means and K-Medoids clustering algorithms. Test results demonstrate the applicability, efficiency and effectiveness of our proposed approach. After extensive experimentation, we conclude that the framework shows promise for further research and specialized commercial applications.},
archivePrefix = {arXiv},
arxivId = {1504.0191},
author = {Roul, Rajendra Kumar and Asthana, Shubham Rohan and Sahay, Sanjay Kumar},
doi = {10.1109/ICHPCA.2014.7045347},
eprint = {1504.0191},
file = {:Users/mendonca/mestrado/projeto{\_}pesquisa/artigos/1504.00191v1.pdf:pdf},
isbn = {9781479959587},
journal = {2014 International Conference on High Performance Computing and Applications, ICHPCA 2014},
keywords = {Hierarchical Clustering,Indexing,Latent Dirichlet Allocation,Latent Semantic Indexing,Topic Modeling},
title = {{Automated document indexing via intelligent hierarchical clustering: A novel approach}},
year = {2015}
}
@article{Udell2005,
abstract = {This article discusses the plan of IBM to open source its Unstructured Information Management Architecture (UIMA) software development kit in the U.S. in 2005. The software provides a framework for coordinating different text analyzers. Each runs as a service that consumes and produces data in common formats. Applications are composed by declaratively combining sets of analyzers. UIMA assumes that people cannot and will not compose texts using semantic markup to denote entities and relations. It also assumes that the semantic clues that can be found on the public Web would not be as available in the enterprise. As blogging begins to play a role in enterprise knowledge management, two strategies will present themselves: social tagging and microformats.},
author = {Udell, Jon},
file = {:Users/mendonca/mestrado/projeto{\_}pesquisa/artigos/ContentServer.pdf:pdf},
journal = {1803072320050822},
keywords = {BLOGS,IBM software,INFORMATION resources management,INTERNATIONAL Business Machines Corp,SEMANTICS,UNITED States},
pages = {30},
title = {{UIMA and the Blogosphere}},
url = {http://search-ebscohost-com.ez67.periodicos.capes.gov.br/login.aspx?direct=true{\&}db=iih{\&}AN=18030723{\&}lang=pt-br{\&}site=ehost-live},
year = {2005}
}
@article{Yasotha2016,
author = {Yasotha, R. and Charles, E. Y A},
doi = {10.1109/IntelCIS.2015.7397271},
file = {:Users/mendonca/Downloads/07397271.pdf:pdf;:Users/mendonca/Library/Application Support/Mendeley Desktop/Downloaded/Yasotha, Charles - 2016 - Automated text document categorization.pdf:pdf},
isbn = {9781509019496},
journal = {2015 IEEE 7th International Conference on Intelligent Computing and Information Systems, ICICIS 2015},
keywords = {ACM,ACM-CCS,LDA,Latent Dirichlet Allocation,document classification,text categorization},
pages = {522--528},
title = {{Automated text document categorization}},
year = {2016}
}

@article{Kaleta2014,
abstract = {The following article presents a specific issue of semantic analysis of texts in natural language – text indexing and describes one field of its application (web browsing). The main part of this article describes a computer system assigning a set of semantic indexes (similar to keywords) to a particular text. The indexing algorithm employs a semantic dictionary to find specific words in a text that represent a text content. Furthermore, it compares two given sets of semantic indexes to determine similarities between texts (assigning a numerical value). The article describes the semantic dictionary – a tool essential to accomplish this task and its usefulness, the main concepts of the algorithm, and the test results.},
journal = {Computer Science},
author = {Kaleta, Zbigniew},
doi = {http://dx.doi.org/10.7494/csci.2014.15.1.19},
file = {:Users/mendonca/Downloads/148-2851-1-PB.pdf:pdf},
keywords = {indexing,semantic analysis,text subject},
number = {1},
title = {{Semantic text indexing}},
volume = {15},
year = {2014}
}

@misc{Fallows,
  title = {{The Internet and Daily Life} Many Americans use the Internet in everyday activities, but traditional offline habits still dominate},
 author = {Deborah Fallows},
  howpublished = {\url{http://www.pewinternet.org/files/old-media/Files/Reports/2004/PIP_Internet_and_Daily_Life.pdf.pdf}},
  year = {2004},
  note = {Accessed: 2016-11-08}
}

@article{Milne2012,
author = {Milne, David and Witten, Ian H},
doi = {10.1016/j.artint.2012.06.007},
file = {:Users/mendonca/mestrado/projeto{\_}pesquisa/artigos/10.1.1.299.9904.pdf:pdf},
issn = {0004-3702},
journal = {Artificial Intelligence},
pages = {1--18},
publisher = {Elsevier B.V.},
title = {{An open-source toolkit for mining Wikipedia}},
url = {http://dx.doi.org/10.1016/j.artint.2012.06.007},
volume = {1},
year = {2012}
}

@INPROCEEDINGS{Milne,
    author = {David Milne},
    title = {An open-source toolkit for mining wikipedia},
    booktitle = {In Proc. New Zealand Computer Science Research Student Conf},
    year = {2012},
    pages = {2009}
}

@article{ICWSM09154,
author = {Mathieu Bastian and Sebastien Heymann and Mathieu Jacomy},
title = {Gephi: An Open Source Software for Exploring and Manipulating Networks},
conference = {International AAAI Conference on Weblogs and Social Media},
year = {2009},
journal = {International AAAI Conference on Web and Social Media
Third International AAAI Conference on Weblogs and Social Media},
keywords = {network;network science;visualization;graph exploration;open source;free software;dynamic network;interactive interface;graph;force vector;java;OpenGL;3-D visualization;user-centric;graph layout;complex graph rendering;network analysis;webatlas},
abstract = {Gephi is an open source software for graph and network analysis. It uses a 3D render engine to display large networks in real-time and to speed up the exploration. A flexible and multi-task architecture brings new possibilities to work with complex data sets and produce valuable visual results. We present several key features of Gephi in the context of interactive exploration and interpretation of networks. It provides easy and broad access to network data and allows for spatializing, filtering, navigating, manipulating and clustering. Finally, by presenting dynamic features of Gephi, we highlight key aspects of dynamic network visualization.},
url = {http://www.aaai.org/ocs/index.php/ICWSM/09/paper/view/154}
}


@book{Krippendorff2012,
	Address = {Thousand Oaks, CA},
	Author = {Klaus Krippendorff},
	Edition = {3},
	Publisher = {SAGE Publications, Inc},
	Title = {Content Analysis: An Introduction to Its Methodology},
	Year = {2012}}

@article{Turney:2000:LAK:593957.593993,
	 author = {Turney, Peter D.},
	 title = {Learning Algorithms for Keyphrase Extraction},
	 journal = {Inf. Retr.},
	 issue_date = {May 2000},
	 volume = {2},
	 number = {4},
	 month = may,
	 year = {2000},
	 issn = {1386-4564},
	 pages = {303--336},
	 numpages = {34},
	 url = {http://dx.doi.org/10.1023/A:1009976227802},
	 doi = {10.1023/A:1009976227802},
	 acmid = {593993},
	 publisher = {Kluwer Academic Publishers},
	 address = {Hingham, MA, USA},
	 keywords = {indexing, keyphrase extraction, keywords, machine learning, summarization}}
	 
@inproceedings{mihalcea-tarau:2004:EMNLP,
    author = {Mihalcea, Rada and Tarau, Paul},
    url = {http://www.aclweb.org/anthology/W04-3252},
    title = {TextRank: Bringing Order into Texts},
    booktitle = {Proceedings of EMNLP 2004},
    editor = {Dekang Lin and Dekai Wu},
    year = {2004},
    month = {July},
    address = {Barcelona, Spain},
    publisher = {Association for Computational Linguistics},
    pages = {404--411}}